name: Build SmartNews Feed
on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - "feed.xml"
      - ".github/workflows/fetch-feed.yml"
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours to fetch new articles

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libxml2-utils python3 python3-pip
          pip3 install feedparser requests beautifulsoup4 lxml
      
      - name: Fetch and enhance feed
        run: |
          cat > enhance_feed.py << 'PYTHON_SCRIPT'
          import feedparser
          import requests
          from bs4 import BeautifulSoup
          import xml.etree.ElementTree as ET
          from datetime import datetime
          import re
          
          # Parse existing feed
          tree = ET.parse('feed.xml')
          root = tree.getroot()
          
          # Register namespaces
          namespaces = {
              'content': 'http://purl.org/rss/1.0/modules/content/',
              'dc': 'http://purl.org/dc/elements/1.1/',
              'media': 'http://search.yahoo.com/mrss/',
              'snf': 'http://www.smartnews.com/snf'
          }
          
          for prefix, uri in namespaces.items():
              ET.register_namespace(prefix, uri)
          
          channel = root.find('channel')
          
          # Get current items
          existing_items = channel.findall('item')
          print(f"Current items in feed: {len(existing_items)}")
          
          # Add snf:analytics to each existing item if missing
          analytics_url = 'https://analytics.smartnews.com/track?u=${snf_url}'
          
          for item in existing_items:
              # Check if snf:analytics already exists
              analytics = item.find('snf:analytics', namespaces)
              if analytics is None:
                  # Add snf:analytics tag
                  analytics = ET.SubElement(item, '{http://www.smartnews.com/snf}analytics')
                  analytics.text = analytics_url
                  print(f"Added snf:analytics to: {item.find('title').text}")
          
          # If we have fewer than 20 items, try to fetch more from the source
          if len(existing_items) < 20:
              print(f"Attempting to fetch more articles (current: {len(existing_items)}, target: 20)")
              
              # Fetch the original RSS feed
              try:
                  source_feed_url = 'https://www.cabletv.com/blog/category/entertainment/feed/'
                  response = requests.get(source_feed_url, timeout=10)
                  source_feed = feedparser.parse(response.content)
                  
                  # Get existing GUIDs to avoid duplicates
                  existing_guids = set()
                  for item in existing_items:
                      guid = item.find('guid')
                      if guid is not None:
                          existing_guids.add(guid.text)
                  
                  # Add new items up to 20 total
                  added_count = 0
                  for entry in source_feed.entries[:25]:  # Check more entries
                      if len(existing_items) + added_count >= 20:
                          break
                      
                      # Create a GUID (use link as fallback)
                      entry_guid = getattr(entry, 'id', entry.link)
                      
                      if entry_guid not in existing_guids:
                          # Create new item
                          new_item = ET.SubElement(channel, 'item')
                          
                          # Add title
                          title = ET.SubElement(new_item, 'title')
                          title.text = entry.title
                          
                          # Add link
                          link = ET.SubElement(new_item, 'link')
                          link.text = entry.link
                          
                          # Add guid
                          guid = ET.SubElement(new_item, 'guid')
                          guid.text = entry_guid
                          
                          # Add pubDate
                          pub_date = ET.SubElement(new_item, 'pubDate')
                          if hasattr(entry, 'published_parsed') and entry.published_parsed:
                              pub_date.text = datetime(*entry.published_parsed[:6]).strftime('%a, %d %b %Y %H:%M:%S GMT')
                          else:
                              pub_date.text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
                          
                          # Add author
                          if hasattr(entry, 'author'):
                              author = ET.SubElement(new_item, '{http://purl.org/dc/elements/1.1/}creator')
                              author.text = entry.author
                          
                          # Add content
                          content_encoded = ET.SubElement(new_item, '{http://purl.org/rss/1.0/modules/content/}encoded')
                          
                          # Try to get full content
                          if hasattr(entry, 'content') and len(entry.content) > 0:
                              full_content = entry.content[0].value
                          elif hasattr(entry, 'summary'):
                              full_content = entry.summary
                          else:
                              full_content = entry.description if hasattr(entry, 'description') else ''
                          
                          content_encoded.text = full_content
                          
                          # Add thumbnail if available
                          if hasattr(entry, 'media_thumbnail') and len(entry.media_thumbnail) > 0:
                              thumbnail = ET.SubElement(new_item, '{http://search.yahoo.com/mrss/}thumbnail')
                              thumbnail.set('url', entry.media_thumbnail[0]['url'])
                          elif hasattr(entry, 'media_content') and len(entry.media_content) > 0:
                              thumbnail = ET.SubElement(new_item, '{http://search.yahoo.com/mrss/}thumbnail')
                              thumbnail.set('url', entry.media_content[0]['url'])
                          
                          # Add snf:analytics
                          analytics = ET.SubElement(new_item, '{http://www.smartnews.com/snf}analytics')
                          analytics.text = analytics_url
                          
                          added_count += 1
                          print(f"Added new article: {entry.title}")
                  
                  print(f"Added {added_count} new articles")
              except Exception as e:
                  print(f"Error fetching additional articles: {e}")
          
          # Write the updated feed
          tree.write('feed.xml', encoding='utf-8', xml_declaration=True)
          print(f"Final feed has {len(channel.findall('item'))} items")
          
          PYTHON_SCRIPT
          
          python3 enhance_feed.py
      
      - name: Validate XML
        run: |
          xmllint --noout feed.xml || (echo "❌ feed.xml is not well-formed XML." && exit 1)
          echo "✅ feed.xml is well-formed."
      
      - name: Normalize SmartNews namespace
        run: |
          set -euo pipefail
          
          # Ensure correct SmartNews namespace
          sed -i 's~xmlns:snf="[^"]*smartnews\.be/snf"~xmlns:snf="http://www.smartnews.com/snf"~g' feed.xml
          sed -i 's~xmlns:snf="https\?://smartnews\.com/snf"~xmlns:snf="http://www.smartnews.com/snf"~g' feed.xml
          grep -q 'xmlns:snf="http://www.smartnews.com/snf"' feed.xml || \
            sed -i '1s~<rss ~<rss xmlns:snf="http://www.smartnews.com/snf" ~' feed.xml
          
          echo "✅ Namespace normalized"
      
      - name: Validate SmartNews requirements
        run: |
          echo "Validating SmartNews requirements..."
          
          # Check namespace
          if ! grep -q 'xmlns:snf="http://www.smartnews.com/snf"' feed.xml; then
            echo "❌ Missing SmartNews namespace"
            exit 1
          fi
          
          # Count items and analytics tags
          ITEM_COUNT=$(grep -o '<item>' feed.xml | wc -l | tr -d '[:space:]')
          ANALYTICS_COUNT=$(grep -o '<snf:analytics>' feed.xml | wc -l | tr -d '[:space:]')
          
          echo "Items: $ITEM_COUNT"
          echo "Analytics tags: $ANALYTICS_COUNT"
          
          if [ "$ANALYTICS_COUNT" -eq 0 ]; then
            echo "❌ No snf:analytics tags found"
            exit 1
          fi
          
          if [ "$ANALYTICS_COUNT" -ne "$ITEM_COUNT" ]; then
            echo "⚠️  Warning: Item count ($ITEM_COUNT) doesn't match analytics count ($ANALYTICS_COUNT)"
          fi
          
          echo "✅ Validation passed"
      
      - name: Commit changes if modified
        run: |
          if git diff --quiet feed.xml; then
            echo "No changes to commit"
          else
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git pull --rebase origin main || echo "No remote changes"
            git add feed.xml
            git commit -m "ci: update feed with snf:analytics and additional articles"
            
            # Push with retry
            MAX_RETRIES=3
            RETRY_COUNT=0
            until git push origin main || [ $RETRY_COUNT -eq $MAX_RETRIES ]; do
              RETRY_COUNT=$((RETRY_COUNT+1))
              echo "Push failed, retrying ($RETRY_COUNT/$MAX_RETRIES)..."
              sleep 2
              git pull --rebase origin main
            done
          fi
      
      - name: Upload artifact for Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: .
  
  deploy:
    runs-on: ubuntu-latest
    needs: build
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
